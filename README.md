# Dimensionality-Reduction-Effect-on-Machine-Learning-Models


Handling large and complex datasets has become a challenge in healthcare due to the rapid growth of machine learning (ML). Dimensionality reduction techniques, which simplify data without losing valuable information, have emerged as effective solutions to this problem. This study examined the effectiveness of three dimensionality reduction techniques—Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), and Autoencoders—in improving the performance of various ML algorithms. 
Two different datasets were used in the study: the Pima Indian Dataset from the National Institute of Diabetes and Digestive and Kidney Diseases, which contains data from 768 female patients, and the Behavioral Risk Factor Surveillance System (BRFSS) Dataset provided by the Centers for Disease Control and Prevention, which includes 253,680 survey responses covering various health indicators. The researchers evaluated the impact of these techniques on ML algorithms such as Logistic Regression, Random Forest, XGBoost, Extra Trees, Decision Trees, and Multilayer Perceptron Classifier (MLP).
The results showed that dimensionality reduction significantly improved the performance of ML models. In Dataset 1, combining PCA with Random Forest achieved an accuracy of 84.62% and a recall of 94.44%. Similarly, in Dataset 2, XGBoost enhanced with PCA demonstrated exceptional accuracy of 94.47% and a recall of 99.59%. These results highlight the substantial impact of dimensionality reduction on ML models, especially in complex and high-dimensional data scenarios common in healthcare settings.
